Q1:Not boring movies:

Write a solution to report the movies with an odd-numbered ID and a description that is not "boring".
Return the result table ordered by rating in descending order.

Example 1:

Input: 
Cinema table:
+----+------------+-------------+--------+
| id | movie      | description | rating |
+----+------------+-------------+--------+
| 1  | War        | great 3D    | 8.9    |
| 2  | Science    | fiction     | 8.5    |
| 3  | irish      | boring      | 6.2    |
| 4  | Ice song   | Fantacy     | 8.6    |
| 5  | House card | Interesting | 9.1    |
+----+------------+-------------+--------+
Output: 
+----+------------+-------------+--------+
| id | movie      | description | rating |
+----+------------+-------------+--------+
| 5  | House card | Interesting | 9.1    |
| 1  | War        | great 3D    | 8.9    |
+----+------------+-------------+--------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution:

SELECT *                               -- Selects all columns from the Cinema table
FROM cinema                            -- Specifies the Cinema table as the data source
WHERE id % 2 != 0                      -- Filters movies with an odd id (id is not divisible by 2)
  AND description <> 'boring'          -- Excludes movies where the description is 'boring'
ORDER BY rating DESC;                  -- Orders the results by rating in descending order
---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!
1- Purpose:
This query retrieves movies with odd IDs, excludes those described as 'boring', and sorts them by rating in descending order.

2-Why Use Modulo (%):ü§∑‚Äç‚ôÄ
The modulo operator is a common and efficient way to filter odd or even values. It's simple and easy to understand.

3-<> for Exclusion:
<> is SQL's standard inequality operator, ensuring the query excludes unwanted rows (e.g., movies described as 'boring').

4-Best Practices:
Use SELECT * sparingly and specify required columns for better performance and clarity.
Always document the logic behind filters (e.g., why odd IDs are selected).

5-Real-World Use Case:
This query is suitable for scenarios like filtering and ranking movies in a database for recommendations.
*************************************************************************************************************************************************************************************
Q2: Average selling price:

Write a solution to find the average selling price for each product. average_price should be rounded to 2 decimal places. 
If a product does not have any sold units, its average selling price is assumed to be 0.
Return the result table in any order.

Example 1:

Input: 
Prices table:
+------------+------------+------------+--------+
| product_id | start_date | end_date   | price  |
+------------+------------+------------+--------+
| 1          | 2019-02-17 | 2019-02-28 | 5      |
| 1          | 2019-03-01 | 2019-03-22 | 20     |
| 2          | 2019-02-01 | 2019-02-20 | 15     |
| 2          | 2019-02-21 | 2019-03-31 | 30     |
+------------+------------+------------+--------+
UnitsSold table:
+------------+---------------+-------+
| product_id | purchase_date | units |
+------------+---------------+-------+
| 1          | 2019-02-25    | 100   |
| 1          | 2019-03-01    | 15    |
| 2          | 2019-02-10    | 200   |
| 2          | 2019-03-22    | 30    |
+------------+---------------+-------+
Output: 
+------------+---------------+
| product_id | average_price |
+------------+---------------+
| 1          | 6.96          |
| 2          | 16.96         |
+------------+---------------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution:

-- Selects the product ID from the Prices table
-- Rounds the calculated average price to 2 decimal places
-- Handles NULL values by returning 0 if there are no matching units sold
SELECT p.product_id, ROUND( IFNULL( SUM(p.price * u.units) / SUM(u.units), 0), 2) AS average_price     -- Alias for the calculated average price
                                         
FROM prices p                                                                                          -- Prices table containing product prices and date ranges
LEFT JOIN unitssold u                                                                                  -- LEFT JOIN ensures all products are included, even if no units were sold
ON p.product_id = u.product_id                                                                         -- Matches product IDs between Prices and UnitsSold
   AND u.purchase_date BETWEEN p.start_date AND p.end_date                                             -- Ensures the units sold fall within the valid price date range
GROUP BY p.product_id;                                                                                 -- Groups results by product ID for aggregation
---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!
1-Purpose:
This query calculates the average price per product based on units sold during valid price periods, handling cases where no units were sold.

2-Handling NULL Values with IFNULL:
If no matching records are found in the unitssold table (e.g., no units sold for a product), the IFNULL function ensures the average price is set to 0 instead of NULL.

3-Why Use LEFT JOIN?ü§∑‚Äç‚ôÄÔ∏è
Ensures all products in the prices table are included in the result, even if there are no sales records in the unitssold table.

4-Date Range Filter:
The BETWEEN p.start_date AND p.end_date condition ensures that only units sold during the valid price period are included in the calculation.

5-Aggregation and Rounding:
SUM(p.price * u.units) / SUM(u.units): Calculates the weighted average price per product based on units sold.
ROUND(..., 2): Rounds the result to two decimal places for better readability.

6-GROUP BY:
Groups by p.product_id to compute the average price for each product individually.

7-Real-World Use Case:
This query is useful for analyzing product pricing trends, such as determining the effective price customers paid during a specific period.

üëå Key Takeaways:

üéáData Integration:
Combines data from two tables (prices and unitssold) to calculate weighted averages.

üéáNULL Handling:
Demonstrates the importance of handling missing data using IFNULL.

üéáScalability:
This pattern can be adapted for other weighted average calculations, such as revenue per unit or cost per item.

üéáSQL Best Practices:
Filters and conditions (e.g., BETWEEN) ensure only relevant data is included in the analysis.
Aggregations (SUM) and rounding improve clarity and precision.
*************************************************************************************************************************************************************************************
Q3: Project employees I:

Write an SQL query that reports the average experience years of all the employees for each project, rounded to 2 digits.
Return the result table in any order.

Example 1:

Input: 
Project table:
+-------------+-------------+
| project_id  | employee_id |
+-------------+-------------+
| 1           | 1           |
| 1           | 2           |
| 1           | 3           |
| 2           | 1           |
| 2           | 4           |
+-------------+-------------+
Employee table:
+-------------+--------+------------------+
| employee_id | name   | experience_years |
+-------------+--------+------------------+
| 1           | Khaled | 3                |
| 2           | Ali    | 2                |
| 3           | John   | 1                |
| 4           | Doe    | 2                |
+-------------+--------+------------------+
Output: 
+-------------+---------------+
| project_id  | average_years |
+-------------+---------------+
| 1           | 2.00          |
| 2           | 2.50          |
+-------------+---------------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution:

SELECT p.project_id, ROUND(AVG(e.experience_years), 2) AS average_years             -- Calculates the average experience years for each project, rounded to 2 decimal places                             
       
FROM project p                                                                      -- Project table containing project and employee mappings
JOIN employee e                                                                     -- Employee table containing employee details, including experience years
ON p.employee_id = e.employee_id                                                    -- Joins Project and Employee tables based on employee_id
GROUP BY p.project_id;                                                              -- Groups the result by project ID to calculate the average for each project
---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!

1-JOIN:
Combines the Project table with the Employee table using the employee_id column, allowing access to employee experience years for each project.

2-AVG:
Calculates the average of experience_years for all employees associated with each project.

3-ROUND:
Rounds the calculated average to 2 decimal places for better readability and compliance with the output format.

4-GROUP BY:
Groups the data by project_id, ensuring that the average is calculated for each project separately.

üëå Key Takeaways:

üéáPurpose:
The query calculates the average experience years of all employees for each project, ensuring accurate and formatted results.

üéáWhy Use JOIN?
Combines project and employee data, making it possible to calculate experience years for each project based on employee participation.

üéáAggregation with AVG:
The AVG function is perfect for scenarios requiring average calculations over grouped data.

üéáRounding with ROUND:
Ensures consistency in output formatting (e.g., 2 decimal places), improving presentation and usability.

üéáGROUP BY for Aggregation:
Ensures the calculation of averages for each unique project (project_id).

üéáPerformance Considerations:
Use appropriate indexing (e.g., on employee_id and project_id) to optimize performance, especially for large datasets.
*************************************************************************************************************************************************************************************
Q4: Percentage of users attended a contest:

Write a solution to find the percentage of the users registered in each contest rounded to two decimals.
Return the result table ordered by percentage in descending order. 
In case of a tie, order it by contest_id in ascending order.

Example 1:

Input: 
Users table:
+---------+-----------+
| user_id | user_name |
+---------+-----------+
| 6       | Alice     |
| 2       | Bob       |
| 7       | Alex      |
+---------+-----------+
Register table:
+------------+---------+
| contest_id | user_id |
+------------+---------+
| 215        | 6       |
| 209        | 2       |
| 208        | 2       |
| 210        | 6       |
| 208        | 6       |
| 209        | 7       |
| 209        | 6       |
| 215        | 7       |
| 208        | 7       |
| 210        | 2       |
| 207        | 2       |
| 210        | 7       |
+------------+---------+
Output: 
+------------+------------+
| contest_id | percentage |
+------------+------------+
| 208        | 100.0      |
| 209        | 100.0      |
| 210        | 100.0      |
| 215        | 66.67      |
| 207        | 33.33      |
+------------+------------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution:

SELECT r.contest_id,                                      
       ROUND(COUNT(DISTINCT r.user_id) * 100.0 /           -- Calculates the percentage of registered users
             (SELECT COUNT(DISTINCT u.user_id)             -- Total number of unique users from the Users table
              FROM users u), 2) AS percentage              -- Rounds the percentage to two decimal places
FROM register r                                            -- Register table containing contest-user mappings
GROUP BY r.contest_id                                      -- Groups results by contest ID for aggregation
ORDER BY percentage DESC,                                  -- Orders by percentage in descending order
         r.contest_id ASC;                                 -- Orders by contest ID in ascending order in case of a tie
---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!

1-Purpose:
Calculate the percentage of total users who registered for each contest.

2-Key Steps:
   a.Count Registered Users:
    COUNT(DISTINCT r.user_id) counts unique users registered for each contest.
   b.Total Users:
    (SELECT COUNT(DISTINCT u.user_id) FROM users u) calculates the total number of distinct users from the Users table.
   c.Percentage:
    Multiplies the count of registered users by 100.0 and divides by the total users to compute the percentage.
   d.Rounding:
    ROUND(..., 2) ensures the result is rounded to two decimal places.
3-GROUP BY:
Groups the data by contest_id to compute the percentage for each contest.

4-ORDER BY:
Orders the result by:
   a.percentage DESC: Descending order of percentage.
   b.contest_id ASC: Ascending order of contest_id to resolve ties.

üëå Key Takeaways:

üéáData Aggregation:
Demonstrates the use of COUNT, DISTINCT, and GROUP BY for summarizing data.

üéáSubquery Usage:
Shows how to calculate a total value (total users) for percentage calculations.

üéáAdvanced Sorting:
Includes multiple sorting criteria for ranked output.

üéáSQL Best Practices:
Uses ROUND for consistent formatting and ensures no duplicate counts with DISTINCT.
*************************************************************************************************************************************************************************************
Q5: Queries quality and percentage:

Write a solution to find each query_name, the quality and poor_query_percentage.
Both quality and poor_query_percentage should be rounded to 2 decimal places.
Return the result table in any order.

Example 1:

Input: 
Queries table:
+------------+-------------------+----------+--------+
| query_name | result            | position | rating |
+------------+-------------------+----------+--------+
| Dog        | Golden Retriever  | 1        | 5      |
| Dog        | German Shepherd   | 2        | 5      |
| Dog        | Mule              | 200      | 1      |
| Cat        | Shirazi           | 5        | 2      |
| Cat        | Siamese           | 3        | 3      |
| Cat        | Sphynx            | 7        | 4      |
+------------+-------------------+----------+--------+
Output: 
+------------+---------+-----------------------+
| query_name | quality | poor_query_percentage |
+------------+---------+-----------------------+
| Dog        | 2.50    | 33.33                 |
| Cat        | 0.66    | 33.33                 |
+------------+---------+-----------------------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution:
SELECT 
    query_name,
    ROUND(SUM(rating * 1.0 / position) / COUNT(*), 2) AS quality,                                                -- Calculates the average quality
    ROUND(SUM(CASE WHEN rating < 3 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS poor_query_percentage            -- Calculates poor query percentage
FROM 
    Queries
GROUP BY 
    query_name;

---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!

1-Purpose:
Calculates the quality of a query.
-The ratio of rating / position is computed for each row, summed up, and then averaged.

Why 1.0 / position?:ü§∑‚Äç‚ôÄÔ∏è
-Multiplying by 1.0 ensures floating-point division for accurate calculations.
-ROUND(SUM(CASE WHEN rating < 3 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2):

2-Purpose:
Calculates the poor query percentage.
-Counts rows where the rating < 3 (poor queries) and divides by the total number of rows for the query.
-Multiplies by 100 to get the percentage.

Why Use CASE?:ü§∑‚Äç‚ôÄÔ∏è
-Enables conditional aggregation, counting only rows that satisfy the condition (rating < 3).

3-GROUP BY query_name:
Ensures metrics are calculated separately for each unique query_name.

4-Rounding with ROUND(..., 2):
Ensures the output matches the required format (two decimal places), making results user-friendly and consistent.

5-Real-World Use Case:
Useful for analyzing the performance of queries in a database or search system:

6-Quality: Evaluates the efficiency of query results based on ratings and relevance (position).
Poor Query Percentage: Helps identify queries needing improvement.


üëå Key Takeaways:

üéáConditional Aggregation:
Demonstrates how to calculate metrics conditionally using CASE.

üéáMathematical Precision:
Ensures calculations are precise by converting integers to floating-point numbers where necessary.

üéáPractical Application:
Highlights a use case in database or search query analysis, making it relatable and applicable.

üéáBest Practices:
Includes ROUND for formatting consistency.
Uses clear aliases (quality, poor_query_percentage) for better readability.

üéáScalable Design:
Works well with small and large datasets, provided proper indexing is in place.
*************************************************************************************************************************************************************************************
Q6: Monthly transactions:

Write an SQL query to find for each month and country, the number of transactions and their total amount, the number of approved transactions and their total amount.
Return the result table in any order.

Example 1:

Input: 
Transactions table:
+------+---------+----------+--------+------------+
| id   | country | state    | amount | trans_date |
+------+---------+----------+--------+------------+
| 121  | US      | approved | 1000   | 2018-12-18 |
| 122  | US      | declined | 2000   | 2018-12-19 |
| 123  | US      | approved | 2000   | 2019-01-01 |
| 124  | DE      | approved | 2000   | 2019-01-07 |
+------+---------+----------+--------+------------+
Output: 
+----------+---------+-------------+----------------+--------------------+-----------------------+
| month    | country | trans_count | approved_count | trans_total_amount | approved_total_amount |
+----------+---------+-------------+----------------+--------------------+-----------------------+
| 2018-12  | US      | 2           | 1              | 3000               | 1000                  |
| 2019-01  | US      | 1           | 1              | 2000               | 2000                  |
| 2019-01  | DE      | 1           | 1              | 2000               | 2000                  |
+----------+---------+-------------+----------------+--------------------+-----------------------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution: 

SELECT 
    DATE_FORMAT(trans_date, '%Y-%m') AS month,                
    country,                                                  
    COUNT(*) AS trans_count,                                                               -- Counts the total number of transactions
    SUM(CASE WHEN state = 'approved' THEN 1 ELSE 0 END) AS approved_count,                 -- Counts the number of approved transactions
    SUM(amount) AS trans_total_amount,                                                     -- Sums the total transaction amount
    SUM(CASE WHEN state = 'approved' THEN amount ELSE 0 END) AS approved_total_amount      -- Sums the total amount of approved transactions

FROM 
    Transactions                                                                           -- Source table containing transaction data
GROUP BY 
    DATE_FORMAT(trans_date, '%Y-%m'), country                                              -- Groups by month and country
ORDER BY 
    month, country;   
---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!

1-DATE_FORMAT(trans_date, '%Y-%m'):
Extracts the year and month from the trans_date column in the format YYYY-MM.

2-COUNT(*):
Counts all rows in the group, representing the total number of transactions for each month and country.

3-SUM(CASE WHEN state = 'approved' THEN 1 ELSE 0 END):
Conditionally counts only the approved transactions.

4-SUM(amount):
Sums the amount column to calculate the total transaction amount.

5-SUM(CASE WHEN state = 'approved' THEN amount ELSE 0 END):
Sums the transaction amounts where the state is 'approved'.

6-GROUP BY:
Groups the rows by the extracted month and country to calculate metrics for each combination.

7-ORDER BY:
Sorts the results by month and country for readability.

üëåKey Takeaways:

üéáDate Aggregation:
DATE_FORMAT(trans_date, '%Y-%m') efficiently extracts the month and year, enabling grouping by time periods.

üéáConditional Aggregation:
CASE WHEN ... THEN ... ELSE ... END allows for selective counting or summing based on conditions, e.g., counting only approved transactions.

üéáSummarization:
Using COUNT(*) and SUM() in combination with GROUP BY helps summarize data for multiple metrics in a single query.

üéáDynamic Metrics:
The query calculates multiple metrics (transaction count, total amount, approved count, approved total amount) simultaneously for each group (month and country).

üéáScalability:
This query design works efficiently for large datasets, provided proper indexing on trans_date and country.

üéáReal-World Application:
Useful in financial or sales reporting to track transaction metrics over time and across regions.

üéáClarity and Readability:
Using descriptive column aliases (trans_count, approved_total_amount) makes the result table self-explanatory.
*************************************************************************************************************************************************************************************
Q7: Immediate food delivery:

Write a solution to find the percentage of immediate orders in the first orders of all customers, rounded to 2 decimal places.


Input: 
Delivery table:
+-------------+-------------+------------+-----------------------------+
| delivery_id | customer_id | order_date | customer_pref_delivery_date |
+-------------+-------------+------------+-----------------------------+
| 1           | 1           | 2019-08-01 | 2019-08-02                  |
| 2           | 2           | 2019-08-02 | 2019-08-02                  |
| 3           | 1           | 2019-08-11 | 2019-08-12                  |
| 4           | 3           | 2019-08-24 | 2019-08-24                  |
| 5           | 3           | 2019-08-21 | 2019-08-22                  |
| 6           | 2           | 2019-08-11 | 2019-08-13                  |
| 7           | 4           | 2019-08-09 | 2019-08-09                  |
+-------------+-------------+------------+-----------------------------+
Output: 
+----------------------+
| immediate_percentage |
+----------------------+
| 50.00                |
+----------------------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution: 

WITH FirstOrders AS (                                               
    SELECT customer_id, MIN(order_date) AS first_order_date                                     -- Finds the earliest order date for each customer                     
    FROM Delivery
    GROUP BY customer_id),                                                                      -- Groups the results by customer

ImmediateOrders AS (SELECT f.customer_id,d.order_date,d.customer_pref_delivery_date             -- Selects the customer ID from FirstOrders
    FROM FirstOrders f                                                                          
    JOIN Delivery d                                                                             -- Joins to get full details of the first order
    ON f.customer_id = d.customer_id AND f.first_order_date = d.order_date                      -- Matches on customer ID
    WHERE d.order_date = d.customer_pref_delivery_date)                                         -- Filters for immediate orders (order date matches delivery date)

SELECT                                                                                          -- Calculates the percentage of immediate first orders, rounded to 2 decimal places
    ROUND(COUNT(DISTINCT ImmediateOrders.customer_id) * 100.0 / COUNT(DISTINCT FirstOrders.customer_id), 2) AS immediate_percentage
FROM FirstOrders                                                                                -- Base CTE with all customers and their first orders
LEFT JOIN ImmediateOrders                                                                       -- Left join to include all customers, even if they don't have immediate orders
ON FirstOrders.customer_id = ImmediateOrders.customer_id;                                       -- Joins to include immediate order details
---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!

1-FirstOrders CTE:
          -Purpose: Extract the first order date for each customer using MIN(order_date).
          -Tip: Use GROUP BY to group data by customer_id for individual customer calculations.

2-ImmediateOrders CTE:
          -Purpose: Identifies customers whose first orders are immediate (i.e., order_date equals customer_pref_delivery_date).
          -Tip: Using a JOIN with conditions ensures that only relevant rows are retained for immediate orders.

3-Main Query:
          -Percentage Calculation:
          -Numerator: Counts customers with immediate first orders using COUNT(DISTINCT ImmediateOrders.customer_id).
          -Denominator: Counts all customers using COUNT(DISTINCT FirstOrders.customer_id).
          -Tip: Use ROUND to ensure results are formatted to two decimal places.
4-Left Join:
          -Ensures all customers from FirstOrders are included, even if they do not have immediate orders.

5-Performance Optimization:
          -Add indexes on customer_id and order_date in the Delivery table for faster grouping and filtering.

6-Real-World Use Case:
          -This query is helpful for businesses analyzing delivery performance metrics, such as how often customers' preferred delivery timelines are met on their first orders.

üëåKey Takeaways:

üéáCTEs (Common Table Expressions):
FirstOrders and ImmediateOrders make the query modular and easier to understand.

üéáConditional Aggregation:
Using CASE in aggregation (e.g., COUNT) filters specific conditions dynamically.

üéáRounding for Precision:
ROUND ensures the result is user-friendly and formatted appropriately.

üéáBusiness Insight:
This query demonstrates how to calculate customer delivery metrics, a common logistics and customer service analytics requirement.
*************************************************************************************************************************************************************************************
Q8:Game play analysis IV:

Write a solution to report the fraction of players that logged in again on the day after the day they first logged in, 
rounded to 2 decimal places. 
In other words, you need to count the number of players that logged in for at least two consecutive days starting from their first login date, 
then divide that number by the total number of players.

Input: 
Activity table:
+-----------+-----------+------------+--------------+
| player_id | device_id | event_date | games_played |
+-----------+-----------+------------+--------------+
| 1         | 2         | 2016-03-01 | 5            |
| 1         | 2         | 2016-03-02 | 6            |
| 2         | 3         | 2017-06-25 | 1            |
| 3         | 1         | 2016-03-02 | 0            |
| 3         | 4         | 2018-07-03 | 5            |
+-----------+-----------+------------+--------------+
Output: 
+-----------+
| fraction  |
+-----------+
| 0.33      |
+-----------+
---------------------------------------------------------------------------------------------------------------------------------------------------------
Solution: 

WITH FirstLogin AS (
    SELECT player_id, MIN(event_date) AS first_login_date
    FROM Activity
    GROUP BY player_id),

NextDayLogin AS (
    SELECT f.player_id,f.first_login_date,a.event_date
    FROM FirstLogin f
    JOIN Activity a
    ON  f.player_id = a.player_id AND a.event_date = DATE_ADD(f.first_login_date, INTERVAL 1 DAY)),

Fraction AS (SELECT 
                      COUNT(DISTINCT n.player_id) AS next_day_players,
                      COUNT(DISTINCT f.player_id) AS total_players
    FROM FirstLogin f
    LEFT JOIN NextDayLogin n
    ON f.player_id = n.player_id)

SELECT ROUND(next_day_players * 1.0 / total_players, 2) AS fraction
FROM Fraction;
---------------------------------------------------------------------------------------------------------------------------------------------------------
üéØTips!

1-Use CTEs for Modularity:
Breaking the query into logical parts (FirstLogin, NextDayLogin, and Fraction) makes it easier to read, debug, and maintain.

2-MIN for First Event:
MIN(event_date) is ideal for finding the earliest event, such as the first login.

3-Date Comparison:
Use DATE_ADD or equivalent functions to calculate "next day" logic.

4-Distinct Counts:
COUNT(DISTINCT ...) ensures unique players are counted for both total players and those logging in the next day.

5-Left Join for Completeness:
Using a LEFT JOIN ensures all players are included, even if they didn't log in the next day.

6-Rounding:
ROUND(..., 2) is essential for formatting the result to two decimal places, as specified in the requirements.

üëåKey Takeaways:

üéáBehavioral Analysis:
The query analyzes player behavior, specifically the likelihood of logging in on consecutive days starting from the first login.

üéáPerformance Considerations:
Indexing player_id and event_date in the Activity table can significantly improve performance, especially with large datasets.

üéáReal-World Application:
Useful for analyzing player retention and engagement in gaming or application analytics.

üéáDynamic Calculations:
Shows how SQL can handle temporal relationships (e.g., comparing dates) dynamically.

üéáPractical Use of SQL Constructs:
Demonstrates efficient use of aggregation, joins, and conditional logic.
*************************************************************************************************************************************************************************************



























































































